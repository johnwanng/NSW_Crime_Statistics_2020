{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as psql\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create database connection\n",
    "from sqlalchemy import create_engine\n",
    "connection = create_engine('postgresql://test:test@localhost/domestic_violence')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      id      premise         relationship       area v_gender     v_age  \\\n",
       "0  25092  Residential              Sibling    Kempsey   Female   40 - 49   \n",
       "1  40200  Residential              Sibling     Sydney   Female   40 - 49   \n",
       "2  47656  Residential   Unknown/Not Stated      Tweed     Male   40 - 49   \n",
       "3  56306  Residential  Not Known To Victim  Lane Cove     Male       60+   \n",
       "4  79668  Residential  Person In Authority     Gwydir     Male  Under 18   \n",
       "\n",
       "      day          time alcoho  month  result  premise_id  v_gender_id  \\\n",
       "0  Sunday  12am - < 6am      N      6       0          16            2   \n",
       "1  Sunday  6am - < 12pm      N      6       1          16            2   \n",
       "2  Sunday  6am - < 12pm      N     12       0          16            1   \n",
       "3  Sunday  6am - < 12pm      N      1       0          16            1   \n",
       "4  Sunday  12pm - < 6pm      N      9       0          16            1   \n",
       "\n",
       "   v_gender_age_id  relationship_id  day_id  time_id  alcohol_id  location_id  \n",
       "0                5                5       7        1           2           60  \n",
       "1                5                5       7        2           2          106  \n",
       "2                5               13       7        2           2          111  \n",
       "3                7               12       7        2           2           66  \n",
       "4                1               10       7        3           2           51  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>premise</th>\n      <th>relationship</th>\n      <th>area</th>\n      <th>v_gender</th>\n      <th>v_age</th>\n      <th>day</th>\n      <th>time</th>\n      <th>alcoho</th>\n      <th>month</th>\n      <th>result</th>\n      <th>premise_id</th>\n      <th>v_gender_id</th>\n      <th>v_gender_age_id</th>\n      <th>relationship_id</th>\n      <th>day_id</th>\n      <th>time_id</th>\n      <th>alcohol_id</th>\n      <th>location_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>25092</td>\n      <td>Residential</td>\n      <td>Sibling</td>\n      <td>Kempsey</td>\n      <td>Female</td>\n      <td>40 - 49</td>\n      <td>Sunday</td>\n      <td>12am - &lt; 6am</td>\n      <td>N</td>\n      <td>6</td>\n      <td>0</td>\n      <td>16</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>40200</td>\n      <td>Residential</td>\n      <td>Sibling</td>\n      <td>Sydney</td>\n      <td>Female</td>\n      <td>40 - 49</td>\n      <td>Sunday</td>\n      <td>6am - &lt; 12pm</td>\n      <td>N</td>\n      <td>6</td>\n      <td>1</td>\n      <td>16</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>2</td>\n      <td>2</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47656</td>\n      <td>Residential</td>\n      <td>Unknown/Not Stated</td>\n      <td>Tweed</td>\n      <td>Male</td>\n      <td>40 - 49</td>\n      <td>Sunday</td>\n      <td>6am - &lt; 12pm</td>\n      <td>N</td>\n      <td>12</td>\n      <td>0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>5</td>\n      <td>13</td>\n      <td>7</td>\n      <td>2</td>\n      <td>2</td>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56306</td>\n      <td>Residential</td>\n      <td>Not Known To Victim</td>\n      <td>Lane Cove</td>\n      <td>Male</td>\n      <td>60+</td>\n      <td>Sunday</td>\n      <td>6am - &lt; 12pm</td>\n      <td>N</td>\n      <td>1</td>\n      <td>0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>7</td>\n      <td>12</td>\n      <td>7</td>\n      <td>2</td>\n      <td>2</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>79668</td>\n      <td>Residential</td>\n      <td>Person In Authority</td>\n      <td>Gwydir</td>\n      <td>Male</td>\n      <td>Under 18</td>\n      <td>Sunday</td>\n      <td>12pm - &lt; 6pm</td>\n      <td>N</td>\n      <td>9</td>\n      <td>0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2</td>\n      <td>51</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dv_dataset = psql.read_sql('SELECT * FROM dv_real_test', connection)\n",
    "\n",
    "dv_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from pandas.plotting import scatter_matrix\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   month  result  premise_id  v_gender_id  v_gender_age_id  relationship_id  \\\n",
       "0      6       0          16            2                5                5   \n",
       "1      6       1          16            2                5                5   \n",
       "2     12       0          16            1                5               13   \n",
       "3      1       0          16            1                7               12   \n",
       "4      9       0          16            1                1               10   \n",
       "\n",
       "   day_id  time_id  alcohol_id  location_id  \n",
       "0       7        1           2           60  \n",
       "1       7        2           2          106  \n",
       "2       7        2           2          111  \n",
       "3       7        2           2           66  \n",
       "4       7        3           2           51  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>month</th>\n      <th>result</th>\n      <th>premise_id</th>\n      <th>v_gender_id</th>\n      <th>v_gender_age_id</th>\n      <th>relationship_id</th>\n      <th>day_id</th>\n      <th>time_id</th>\n      <th>alcohol_id</th>\n      <th>location_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>0</td>\n      <td>16</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n      <td>60</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6</td>\n      <td>1</td>\n      <td>16</td>\n      <td>2</td>\n      <td>5</td>\n      <td>5</td>\n      <td>7</td>\n      <td>2</td>\n      <td>2</td>\n      <td>106</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12</td>\n      <td>0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>5</td>\n      <td>13</td>\n      <td>7</td>\n      <td>2</td>\n      <td>2</td>\n      <td>111</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>7</td>\n      <td>12</td>\n      <td>7</td>\n      <td>2</td>\n      <td>2</td>\n      <td>66</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>0</td>\n      <td>16</td>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>7</td>\n      <td>3</td>\n      <td>2</td>\n      <td>51</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# Drop categorical columns\n",
    "data = dv_dataset.drop([\"id\",\"premise\",\"relationship\",\"area\",\"v_gender\",\"v_age\",\"day\",\"time\",\"alcoho\"], axis=1)\n",
    "feature_names = data.columns\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(76159, 10)\n"
     ]
    }
   ],
   "source": [
    "# drop all rows with any NaN and NaT values\n",
    "data = data.dropna()\n",
    "#76159 instances and 10 attributes:\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[\"result\"]\n",
    "target_names = [\"negative\", \"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop result columns\n",
    "data = data.drop(\"result\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaling = MinMaxScaler(feature_range=(-1,1)).fit(X_train)\n",
    "X_train = scaling.transform(X_train)\n",
    "X_test = scaling.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LR: 0.868765 (0.004146)\n",
      "LDA: 0.843082 (0.003270)\n",
      "KNN: 0.913059 (0.003105)\n",
      "CART: 0.880092 (0.004391)\n",
      "NB: 0.863163 (0.004231)\n",
      "SVM: 0.918486 (0.002157)\n"
     ]
    }
   ],
   "source": [
    "# Spot Check Algorithms\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "models.append(('KNN', KNeighborsClassifier()))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(kernel='linear')))\n",
    "# evaluate each model in turn\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\tkfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\tcv_results = cross_val_score(model, X_train, y_train, cv=kfold, scoring='accuracy')\n",
    "\tresults.append(cv_results)\n",
    "\tnames.append(name)\n",
    "\tprint('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9168067226890756\n[[10934  1035]\n [  549  6522]]\n              precision    recall  f1-score   support\n\n           0       0.95      0.91      0.93     11969\n           1       0.86      0.92      0.89      7071\n\n    accuracy                           0.92     19040\n   macro avg       0.91      0.92      0.91     19040\nweighted avg       0.92      0.92      0.92     19040\n\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on validation dataset with SVM as it yields the best result\n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train, y_train)\n",
    "predictions = model.predict(X_test)\n",
    "# Evaluate predictions\n",
    "print(accuracy_score(y_test, predictions))\n",
    "print(confusion_matrix(y_test, predictions))\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump,load\n",
    "# Saved model and scaler\n",
    "dump(model, open('model.sav', 'wb'))\n",
    "dump(scaling, open('scaler.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1st prediction is: True\n2nd prediction is: False\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "storedModel = load(open('model.sav', 'rb'))\n",
    "# load the scaler\n",
    "storedScaler = load(open('scaler.sav', 'rb'))\n",
    "my_prediction1 = [[4,6,2,5,6,7,1,2,127]]\n",
    "\n",
    "# Prediction 1 Profile\n",
    "# 4 -   Month   :\"April\"\n",
    "# 6 -  Premise :\"Carpark\"\n",
    "# 2 -   Gender  :\"Female\"\n",
    "# 5 -\tVictum Age: \"40 - 49\"\n",
    "# 6 -  Relationship with Victim:   \"Member Of Family - Other\"\t\n",
    "# 7 -   Day     :\"Sunday\"\n",
    "# 1 -   Time    :\"12am - < 6am\"\n",
    "# 2 -   Alcohol :\"N\"\n",
    "# 127 -  Location:\"Wollongong\"\t\n",
    "\n",
    "my_prediction2 = [[3,16,1,4,12,7,4,2,60]]\n",
    "# Prediction 2 Profile\n",
    "# 3 -   Month   :\"March\"\n",
    "# 16 -  Premise :\"Residential\"\n",
    "# 1 -   Gender  :\"Male\"\n",
    "# 4 -\tVictum Age: \"30 - 39\"\n",
    "# 12 -  Relationship with Victim:   \"Not Known To Victim\"\t\n",
    "# 7 -   Day     :\"Sunday\"\n",
    "# 4 -   Time    :\"6pm - < 12pm\"\n",
    "# 2 -   Alcohol :\"N\"\n",
    "# 60 -  Location:\"Kempsey\"\t\n",
    "\n",
    "my_scaled_prediction1 = storedScaler.transform(my_prediction1)\n",
    "my_scaled_prediction2 = storedScaler.transform(my_prediction2)\n",
    "p1 = storedModel.predict(my_scaled_prediction1)\n",
    "p2 = storedModel.predict(my_scaled_prediction2)\n",
    "\n",
    "def result(prediction):\n",
    "    result = 'False'\n",
    "    if prediction[0] == 1:\n",
    "        result = 'True'\n",
    "    return result    \n",
    "\n",
    "print(\"1st prediction is: \" + result(p1))\n",
    "print(\"2nd prediction is: \" + result(p2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the saved model and scaler files\n",
    "\n",
    "# prepare dataset\n",
    "X, y = make_blobs(n_samples=100, centers=2, n_features=2, random_state=1)\n",
    "# split data into train and test sets\n",
    "_, X_test, _, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "# load the model\n",
    "model = load(open('model.pkl', 'rb'))\n",
    "# load the scaler\n",
    "scaler = load(open('scaler.pkl', 'rb'))\n",
    "# check scale of the test set before scaling\n",
    "print('Raw test set range')\n",
    "for i in range(X_test.shape[1]):\n",
    "\tprint('>%d, min=%.3f, max=%.3f' % (i, X_test[:, i].min(), X_test[:, i].max()))\n",
    "# transform the test dataset\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print('Scaled test set range')\n",
    "for i in range(X_test_scaled.shape[1]):\n",
    "\tprint('>%d, min=%.3f, max=%.3f' % (i, X_test_scaled[:, i].min(), X_test_scaled[:, i].max()))\n",
    "# make predictions on the test set\n",
    "yhat = model.predict(X_test_scaled)\n",
    "# evaluate accuracy\n",
    "acc = accuracy_score(y_test, yhat)\n",
    "print('Test Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd03a86e58504f5e3cb3215340ad196333ed979f9c7b64d8af4f1cdf302e1fdb17e",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}